```json
[
  {"secondRange": "00:00-00:06", "transcript": "This is Avatar, and we're going to try to talk to Alan Musk, who is a founder of the Avatar AI digital twin platform.", "frameDescription": "A person is recording a screen showing the ivatar.ai website with three avatars."},
  {"secondRange": "00:06-00:15", "transcript": "So this is Alan Musk. He has a 3D avatar, which means that this is a fully immersive 3D environment and not just a 2D pictures.", "frameDescription": "The screen shows a 3D avatar of Alan Musk on the ivatar.ai website."},
  {"secondRange": "00:15-00:25", "transcript": "Let's try to ask him a couple of questions. And we're going to pin this here, so we know exactly what we're going to talk about. First one, who are you and what are you doing?", "frameDescription": "The person is recording a screen showing the ivatar.ai website with a 3D avatar of Alan Musk."},
  {"secondRange": "00:25-00:27", "transcript": "I'm a startup founder.", "frameDescription": "The 3D avatar of Alan Musk sits down and responds."},
  {"secondRange": "00:27-00:34", "transcript": "Oh, wow, so he's a startup founder and he's sitting down to have a conversation with us, and it's a 3D environment. You can actually see around.", "frameDescription": "The person is recording a screen showing the ivatar.ai website with a 3D avatar of Alan Musk."},
  {"secondRange": "00:34-00:42", "transcript": "Let's ask him a second question to see if he can actually perform some physical action and not just talking. Hey, Alan Musk, can you do some sports?", "frameDescription": "The person is recording a screen showing the ivatar.ai website with a 3D avatar of Alan Musk."},
  {"secondRange": "00:42-00:44", "transcript": "Let's play some sports.", "frameDescription": "The 3D avatar of Alan Musk stands up and responds."},
  {"secondRange": "00:44-00:49", "transcript": "Oh, wow, that's some very sleek move of Alan Musk. Wow. And it just ran closer to me, so maybe let's chill things down a little bit.", "frameDescription": "The person is recording a screen showing the ivatar.ai website with a 3D avatar of Alan Musk."},
  {"secondRange": "00:49-00:57", "transcript": "And ask him to sit down. Can you sit down and have some meals with me?", "frameDescription": "The person is recording a screen showing the ivatar.ai website with a 3D avatar of Alan Musk."},
  {"secondRange": "00:57-00:59", "transcript": "Sorry, I didn't catch that. Could you try again?", "frameDescription": "The 3D avatar of Alan Musk responds."},
  {"secondRange": "00:59-01:03", "transcript": "Wow, so he's being arrogant and yeah, not wanting to sit down.", "frameDescription": "The person is recording a screen showing the ivatar.ai website with a 3D avatar of Alan Musk."},
  {"secondRange": "01:03-01:10", "transcript": "Uh, lastly, let's try to ask him what he thinks about young people and artificial intelligence, which is the topic of our Kazan Youth Summit.", "frameDescription": "The person is recording a screen showing the ivatar.ai website with a 3D avatar of Alan Musk."},
  {"secondRange": "01:10-01:12", "transcript": "Young people love artificial intelligence.", "frameDescription": "The 3D avatar of Alan Musk responds."},
  {"secondRange": "01:12-01:17", "transcript": "He replied, uh, to what we spoke about. So really nice to meet you, Alan Musk. Thank you so much.", "frameDescription": "The person is recording a screen showing the ivatar.ai website with a 3D avatar of Alan Musk."},
  {"secondRange": "01:17-01:18", "transcript": "", "frameDescription": "The person stops recording the screen."},
  {"secondRange": "01:18-01:21", "transcript": "", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "01:21-01:24", "transcript": "Okay, so this is an overview of the demo you just saw.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "01:24-01:27", "transcript": "Everything is located in this NX mono repo. The front end is located in", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "01:27-01:31", "transcript": "Nextjs project app right here. So it basically handles, you know, a lot of", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "01:31-01:36", "transcript": "3js stuff. For example, you know, like loading the 3D model, which is the character.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "01:36-01:40", "transcript": "Right, choosing the character, which is quite manual right now.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "01:40-01:47", "transcript": "And, you know, like accessing the different animations to render them.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "01:47-01:56", "transcript": "Right? So everything happens mostly in this avatar components, uh, which load the character. And below it also handles animation, facial expression and lip sinking as well.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "01:56-02:01", "transcript": "You know, to play them, uh, when you get the response from the server. I guess the most complicated thing that I had to do in this is", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:01-02:12", "transcript": "when you load, uh, different 3D characters, 3D models, the size and the coordinates and the ratio of the bone structure can be different.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:12-02:25", "transcript": "And right now the animations for the actions that the character is using, uh, is actually from an open source library by Adobe.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:25-02:31", "transcript": "So we need to actually normalize that animation to fit the bone frame, uh, of the 3D model that we have.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:31-02:36", "transcript": "So what I did is I wrote this function here, normalize Fx animation.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:36-02:48", "transcript": "And it's very complicated, but it just basically goes over, you know, different notes in the bone structure, um, and compare them to the, you know, the corresponding notes from the animation and try to normalize them to the same level so that when animation goes into, uh, the character it would actually work, right?", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:48-02:49", "transcript": "So that's the front end.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:49-02:51", "transcript": "And then you got like the server, which is, uh,", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:51-02:55", "transcript": "basically just a an express server. Um,", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "02:55-03:01", "transcript": "is a chain of commands that uses Lang chain to process the user message.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "03:01-03:12", "transcript": "And then output a series of LM actions that generates the response, generates the actions, generates the audio and generates the coordinates for lip sinking to be sent back to the 3D model on the front end.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "03:12-03:20", "transcript": "And it's basically like a bunch of command that does that, but I think like one of the thing that stands out and I don't think anyone has done this before is in my chain, you can kind of see that the character is actually", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "03:20-03:28", "transcript": "able to not only lip sinking or respond, but also perform actions that correspond to the content of the reply.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "03:28-03:31", "transcript": "So what's basically happening here is in the handle user message function,", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "03:31-03:36", "transcript": "right? We're generating audio, we're generating response, right? These kinds of stuffs, you know, happens in other apps as well.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "03:36-03:41", "transcript": "Lip sinking, right? And there is a function, the first thing that's called is get relevant actions, right? And it's the first thing that's called.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "03:41-03:51", "transcript": "And what it basically does is it, you know, adds the user message into, um, a rec search, like a vector database search, right? So it initializes a vector database,", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "03:51-04:01", "transcript": "which contains, um, all actions that are available. Right? So for example, here, we are importing animation names.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "04:01-04:07", "transcript": "And it's just right now a static file, right? So it's in the asset folder.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "04:07-04:16", "transcript": "These are all the animation names, which are FBX file and they correspond with, you know, like the the actual FBX file that are so in the database.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "04:16-04:25", "transcript": "So we perform a similarity search to return about 10 to 15 actions that are similar to the user query, right?", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "04:25-04:31", "transcript": "And then after that, uh, after we get like the names of the relevant actions, um, you know, we combine them.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "04:31-04:35", "transcript": "And then it's here, right? So it's pretty close as well. So after we get the the relevant actions,", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "04:35-04:40", "transcript": "choose the companion name and then based on the messages, we will just download the animation URL from the database.", "frameDescription": "The person is recording a screen showing code."},
  {"secondRange": "04:40-04:55", "transcript": "Right? And then load it, uh, the URL into the response, uh, body of the response that the LM returns. But that a little bit, you know, uh, you know, roundabout, but that's basically how it works. That's how the character can actually perform certain actions.", "frameDescription": "The person is recording a screen showing code."}
]
```